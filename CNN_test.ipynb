{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QfFk5ZbC2I90"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "P7MCNeIM2I97"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Constants\n",
        "IMG_WIDTH = 30\n",
        "IMG_HEIGHT = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NWgEob4c2I99"
      },
      "outputs": [],
      "source": [
        "# Functions\n",
        "def get_contours(image):\n",
        "    contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0])\n",
        "    return contours\n",
        "\n",
        "\n",
        "def sort_contours(contours):\n",
        "    base_rect=[]\n",
        "    w=int(IMG_WIDTH)\n",
        "    h=int(IMG_HEIGHT)\n",
        "    for c in contours :\n",
        "        x,y,w,h= cv2.boundingRect(c)\n",
        "        rect=[x,y,w,h]\n",
        "        base_rect.append(rect)\n",
        "    is_true_rect=[]\n",
        "    for r in base_rect:\n",
        "        l=[]\n",
        "        for rec in base_rect:\n",
        "            flag=0\n",
        "            if rec!=r:\n",
        "                if r[0]<(rec[0]+rec[2]+10) and rec[0]<(r[0]+r[2]+10) and r[1]<(rec[1]+rec[3]+10) and rec[1]<(r[1]+r[3]+10):\n",
        "                    flag=1\n",
        "                l.append(flag)\n",
        "            if rec==r:\n",
        "                l.append(0)\n",
        "        is_true_rect.append(l)\n",
        "    shit_rect=[]\n",
        "    for i in range(0,len(contours)):\n",
        "        for j in range(0,len(contours)):\n",
        "            if is_true_rect[i][j]==1:\n",
        "                a1=base_rect[i][2]*base_rect[i][3]\n",
        "                a2=base_rect[j][2]*base_rect[j][3]\n",
        "                if(a1==min(a1,a2)):\n",
        "                    shit_rect.append(base_rect[i])\n",
        "    return [i for i in base_rect if i not in shit_rect]\n",
        "\n",
        "\n",
        "def extract_digits(image, groups):\n",
        "    train_data = []\n",
        "    for r in groups:\n",
        "        x=r[0]\n",
        "        y=r[1]\n",
        "        w=r[2]\n",
        "        h=r[3]\n",
        "        im_crop =image[y:y+h,x:x+w]\n",
        "        \n",
        "        im_resize = cv2.resize(im_crop,(IMG_WIDTH,IMG_HEIGHT))\n",
        "        cv2_imshow(im_resize)\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        im_resize=np.reshape(im_resize,(1,900))\n",
        "        train_data.append(im_resize)\n",
        "    return train_data\n",
        "\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    # Load the image and preprocess it\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image=~image\n",
        "    image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)[1]\n",
        "    contours = get_contours(image)\n",
        "    groups = sort_contours(contours)\n",
        "    digits = extract_digits(image, groups)\n",
        "    result = []\n",
        "    for d in digits:\n",
        "        d=np.array(d)\n",
        "        result.append(model.predict(d))\n",
        "    # Convert the predicted classes to digits\n",
        "    digits = [np.argmax(r) for r in result]\n",
        "    return digits\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pathlib\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp_rVJNw6uFV",
        "outputId": "74491fc3-5b3f-4fa9-abdd-6040a444650c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4lH6tTq12I9_",
        "outputId": "f3f8ae19-d669-4093-ed5e-444cdf04676b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=30x30 at 0x7F0658D94760>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAAAAAAeW/F+AAAAnElEQVR4nI2RsRHCMBAEV0TUItdCSguUIeqgJ2eCDogp4QjswbKs+0GR9De/d/pPIjgpCZjnkXar0ydozYrIF6mQrCxInJxaYQqNK1i4FsnAC9zx3Wuzj3b1uXiHE8nSc7k5+PrnYTT96qb7EViXLdgIvrFH8L+W4U5tR3L0Vls8eO9UvxIrB7Gp0rl59tH21j08wyv23ll38I7NF6daLXCJnCEQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=30x30 at 0x7F066EF90EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAAAAAAeW/F+AAAAY0lEQVR4nGNgQAH//6PymRjwAvpKq+CX1iDFcDQwqP1NgbQPibpZVsFYYQyrGCQZGFDDhfE/hg4U3QwMDGcZGIwhvLPGDHaHGc4wMDAwmGBTTVGYE/TYB/zSV/BZhe6yAY1QANFyEppg+h17AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=30x30 at 0x7F066EF90EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAAAAAAeW/F+AAAAuklEQVR4nIWTIRbCMBBEB97Dx0fj0VU5AudAcZMchSNEoUFzBBBFYz4ij5I06XZd8rs7k2ki/SslAEhqylFVDc8Awf+WwLHE888Fl2LlNS+IrQNr4Jw/19u3y/xt9O5N7QgHSdp0ZSfQaI+AdO+2lckHQ1uhjrVjgJ2F3UqsK/ICK1S9zGYNnLrHn6abw7N+WEIjJ3ng1qXXfHBHL0Bf3PbmaURgqCxMHnzvJQWAlD75b7rWSszkUe59ATbkh/JbJBQ8AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7+3 = 10\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = tf.keras.models.load_model('/content/handwritten_equation_solver.h5')\n",
        "\n",
        "# Predict an example image\n",
        "digits = predict_image('/content/drive/MyDrive/test_photos/test2.jpeg', model)\n",
        "\n",
        "exp = ''\n",
        "for d in digits:\n",
        "  if d < 10:\n",
        "    exp += (str(d))\n",
        "  elif d == 10:\n",
        "    exp += ('+')\n",
        "  elif d == 11:\n",
        "    exp += ('-')\n",
        "  else:\n",
        "    exp += ('*')\n",
        "\n",
        "result = eval(exp)\n",
        "\n",
        "print(f\"{exp} = {result}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "a4e893bbd86c81bede33f49d1a6c2f7ffb00043248e877ffa803d8fabe3e1c6c"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}